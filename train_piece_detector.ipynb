{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "name": "train_piece_detector.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": [
    "# Piece Detector Training — YOLOv8s (12 classes) on Google Colab T4\n",
    "\n",
    "**What this notebook does:**\n",
    "1. Mounts your Google Drive (upload `chess_pieces/` there first).\n",
    "2. Installs `ultralytics`.\n",
    "3. Rewrites `data.yaml` with absolute Colab paths and the correct 12 class names.\n",
    "4. Trains a YOLOv8s piece-detection model for 150 epochs at 640×640.\n",
    "5. Prints per-class and overall validation metrics.\n",
    "6. Downloads `best.pt` → save it as **`piece_detector.pt`** and drop it into `python-ml-service/models/`.\n",
    "\n",
    "---\n",
    "### Before you run\n",
    "* Make sure **Runtime → Change runtime type → GPU (T4)** is selected.\n",
    "* Upload the entire `chess_pieces/` folder to **My Drive** root (i.e. `/content/drive/MyDrive/chess_pieces/`).\n",
    "\n",
    "### Class mapping (must match your YOLO label files exactly)\n",
    "| ID | Class |\n",
    "|---|---|\n",
    "| 0 | black_bishop |\n",
    "| 1 | black_king |\n",
    "| 2 | black_knight |\n",
    "| 3 | black_pawn |\n",
    "| 4 | black_queen |\n",
    "| 5 | black_rook |\n",
    "| 6 | white_bishop |\n",
    "| 7 | white_king |\n",
    "| 8 | white_knight |\n",
    "| 9 | white_pawn |\n",
    "| 10 | white_queen |\n",
    "| 11 | white_rook |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-step1",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1 — Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-mount",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "PIECE_DATASET_ROOT = '/content/drive/MyDrive/chess_pieces'\n",
    "assert os.path.isdir(PIECE_DATASET_ROOT), (\n",
    "    f\"Dataset folder not found at {PIECE_DATASET_ROOT}. \"\n",
    "    \"Upload chess_pieces/ to the root of My Drive.\"\n",
    ")\n",
    "print('Drive mounted. Dataset root confirmed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-step2",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2 — Install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-install",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install ultralytics -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-step3",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3 — Rewrite data.yaml with absolute Colab paths + 12 classes"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-yaml",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "DATA_YAML_PATH = os.path.join(PIECE_DATASET_ROOT, 'data.yaml')\n",
    "\n",
    "# Read existing yaml (keeps roboflow metadata block intact)\n",
    "with open(DATA_YAML_PATH) as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "# Overwrite paths to absolute Colab locations\n",
    "data['train'] = os.path.join(PIECE_DATASET_ROOT, 'train', 'images')\n",
    "data['val']   = os.path.join(PIECE_DATASET_ROOT, 'valid', 'images')\n",
    "data['test']  = os.path.join(PIECE_DATASET_ROOT, 'test',  'images')\n",
    "\n",
    "# Ensure 12-class config is locked in (matches the label files exactly)\n",
    "data['nc'] = 12\n",
    "data['names'] = [\n",
    "    'black_bishop',   # 0\n",
    "    'black_king',     # 1\n",
    "    'black_knight',   # 2\n",
    "    'black_pawn',     # 3\n",
    "    'black_queen',    # 4\n",
    "    'black_rook',     # 5\n",
    "    'white_bishop',   # 6\n",
    "    'white_king',     # 7\n",
    "    'white_knight',   # 8\n",
    "    'white_pawn',     # 9\n",
    "    'white_queen',    # 10\n",
    "    'white_rook',     # 11\n",
    "]\n",
    "\n",
    "with open(DATA_YAML_PATH, 'w') as f:\n",
    "    yaml.dump(data, f, default_flow_style=False)\n",
    "\n",
    "# Print the final yaml for visual verification\n",
    "with open(DATA_YAML_PATH) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-step4",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4 — Verify GPU + dataset integrity"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-verify",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# File counts per split\n",
    "for split in ('train', 'valid', 'test'):\n",
    "    img_dir = os.path.join(PIECE_DATASET_ROOT, split, 'images')\n",
    "    lbl_dir = os.path.join(PIECE_DATASET_ROOT, split, 'labels')\n",
    "    imgs = len([f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
    "    lbls = len([f for f in os.listdir(lbl_dir) if f.endswith('.txt')])\n",
    "    print(f'{split:>6s} — images: {imgs}, labels: {lbls}')\n",
    "\n",
    "# Class-ID distribution across training labels\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "lbl_dir = os.path.join(PIECE_DATASET_ROOT, 'train', 'labels')\n",
    "for fname in os.listdir(lbl_dir):\n",
    "    if not fname.endswith('.txt'):\n",
    "        continue\n",
    "    with open(os.path.join(lbl_dir, fname)) as f:\n",
    "        for line in f:\n",
    "            cls_id = int(line.strip().split()[0])\n",
    "            counter[cls_id] += 1\n",
    "\n",
    "CLASS_NAMES = data['names']\n",
    "print('\\n--- Training label distribution ---')\n",
    "for cls_id in sorted(counter.keys()):\n",
    "    print(f'  {cls_id:>2d}  {CLASS_NAMES[cls_id]:<16s}  {counter[cls_id]:>5d} instances')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-step5",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5 — Train YOLOv8s\n",
    "\n",
    "| Hyper-parameter | Value | Why |\n",
    "|---|---|---|\n",
    "| model | yolov8s.pt | Small — fast on T4, good enough for 12 classes |\n",
    "| epochs | 150 | More epochs than board model because 12 classes need more convergence |\n",
    "| imgsz | 640 | Matches the Roboflow export resolution |\n",
    "| batch | 16 | Safe for T4 16 GB |\n",
    "| device | 0 | First GPU |\n",
    "| patience | 30 | Early-stop window (wider than board because 12 classes) |\n",
    "| lr0 | 0.01 | Default — works well for transfer from COCO |\n",
    "| lrf | 0.01 | Final LR = lr0 × lrf |\n",
    "\n",
    "> If mAP50 plateaus below 0.80 after 80 epochs, consider switching to `yolov8m.pt` (medium).\n",
    "> That will roughly double the training time on T4 but adds ~10 % mAP ceiling."
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-train",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8s.pt')          # pretrained COCO weights\n",
    "\n",
    "results = model.train(\n",
    "    data     = DATA_YAML_PATH,\n",
    "    epochs   = 150,\n",
    "    imgsz    = 640,\n",
    "    batch    = 16,\n",
    "    device   = 0,\n",
    "    patience = 30,                   # early stopping\n",
    "    lr0      = 0.01,\n",
    "    lrf      = 0.01,\n",
    "    project  = '/content/runs',\n",
    "    name     = 'piece_detection',\n",
    "    verbose  = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-step6",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6 — Overall validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-metrics-overall",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = model.metrics\n",
    "print('\\n===== Piece Detector — Overall Validation Metrics =====')\n",
    "print(f\"  mAP50      : {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP50-95   : {metrics.box.map:.4f}\")\n",
    "print(f\"  Precision  : {metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall     : {metrics.box.mr:.4f}\")\n",
    "print('=======================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-step7",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7 — Per-class validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-metrics-perclass",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ultralytics stores per-class AP in metrics.box.ap (list, one entry per class)\n",
    "ap_list = metrics.box.ap50  # AP@IoU=0.5 per class\n",
    "\n",
    "print('\\n--- Per-Class AP@0.5 ---')\n",
    "print(f'{\"Class\":<18s} {\"AP50\":>8s}')\n",
    "print('-' * 28)\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    val = ap_list[i] if i < len(ap_list) else float('nan')\n",
    "    flag = '  ⚠ low' if val < 0.70 else ''\n",
    "    print(f'{name:<18s} {val:>7.3f}{flag}')\n",
    "print('-' * 28)\n",
    "print(f'{\"Mean\":<18s} {sum(ap_list)/len(ap_list):>7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-step8",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8 — Validate on the held-out test set"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-test-val",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_results = model.val(\n",
    "    data   = DATA_YAML_PATH,\n",
    "    split  = 'test',\n",
    "    imgsz  = 640,\n",
    "    device = 0,\n",
    ")\n",
    "print('\\n===== Test-Set Metrics =====')\n",
    "print(f\"  mAP50      : {test_results.box.map50:.4f}\")\n",
    "print(f\"  mAP50-95   : {test_results.box.map:.4f}\")\n",
    "print(f\"  Precision  : {test_results.box.mp:.4f}\")\n",
    "print(f\"  Recall     : {test_results.box.mr:.4f}\")\n",
    "print('============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-step9",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9 — Visual sample predictions on test images"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-predict",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import display, Image as IPImage\n",
    "import glob\n",
    "\n",
    "test_imgs = sorted(glob.glob(os.path.join(PIECE_DATASET_ROOT, 'test', 'images', '*.*')))\n",
    "sample    = test_imgs[:6]          # 6 sample images\n",
    "\n",
    "pred_results = model.predict(\n",
    "    source = sample,\n",
    "    save   = True,\n",
    "    show   = False,\n",
    "    device = 0,\n",
    "    conf   = 0.3,                   # lower conf for visual review\n",
    ")\n",
    "\n",
    "pred_dir = sorted(glob.glob('/content/runs/predict*'))[-1]\n",
    "for img_path in sorted(glob.glob(os.path.join(pred_dir, '*.*'))):\n",
    "    display(IPImage(filename=img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-step10",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 10 — Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-confusion",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ultralytics saves a confusion_matrix.png in the val output folder\n",
    "import glob\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "cm_files = sorted(glob.glob('/content/runs/piece_detection/val*/confusion_matrix.png'))\n",
    "if cm_files:\n",
    "    display(IPImage(filename=cm_files[-1]))\n",
    "else:\n",
    "    print('Confusion matrix image not found — check /content/runs/piece_detection/val*/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-step11",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 11 — Download best.pt\n",
    "\n",
    "This downloads **`best.pt`** to your browser.\n",
    "Save it as **`piece_detector.pt`** and place it in:\n",
    "`python-ml-service/models/piece_detector.pt`"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-download",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "BEST_PT = '/content/runs/piece_detection/weights/best.pt'\n",
    "assert os.path.isfile(BEST_PT), (\n",
    "    f'best.pt not found at {BEST_PT}. '\n",
    "    'Check /content/runs/ manually.'\n",
    ")\n",
    "\n",
    "files.download(BEST_PT)\n",
    "print('Download started. Save the file as  piece_detector.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-done",
   "metadata": {},
   "source": [
    "---\n",
    "### Done\n",
    "Place the downloaded file at:\n",
    "```\n",
    "ThesisBookProject/\n",
    "  └── python-ml-service/\n",
    "        └── models/\n",
    "              └── piece_detector.pt   ← here\n",
    "```\n",
    "\n",
    "### Troubleshooting\n",
    "| Symptom | Fix |\n",
    "|---|---|\n",
    "| mAP50 < 0.75 after 150 epochs | Switch to `yolov8m.pt` in Step 5 and re-run |\n",
    "| One class dominates errors | Check label count (Step 4 printout); consider class weights or oversampling |\n",
    "| OOM on T4 | Reduce `batch` to 8 |\n",
    "| \"RuntimeError: CUDA\" | Restart runtime, re-run from Step 1 |"
   ]
  }
 ]
}
